{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸BE WARNED! You will not be able to access smule.com from the same PC for at least half an hour after you run this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“ŒIf you want to request data from >1 user, you will need to use VPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from config import id_1, id_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store all the data output\n",
    "mining_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building url\n",
    "user_1 = f'https://www.smule.com/s/profile/performance/{id_1}/sing?offset='\n",
    "user_2 = f'https://www.smule.com/s/profile/performance/{id_2}/sing?offset='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for while loop\n",
    "n = 0\n",
    "\n",
    "# Starting page for request\n",
    "offset = 0 \n",
    "# NOTE: You will need to change the offset if the while loop doesn't finish in the next block. \n",
    "# Get the last next_offset from the print message before the request becomes unsuccessful.\n",
    "# For re-requesting, comment out the n = 0 if you want to see the total amount of request ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the songs the two singers sang togehter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id_1 is the VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infinite loop until the list is empty (offset ran out)\n",
    "\n",
    "while True:\n",
    "    response = requests.get(f'{user_1}{offset}')\n",
    "    print(f'response code: {response.status_code}')\n",
    "    \n",
    "    # Get out of the loop if request is unsuccessful\n",
    "    if response.status_code != 200:\n",
    "        print('Unsuccessful Request T^T')\n",
    "        break\n",
    "    \n",
    "    # Continue to data request\n",
    "    response_json = response.json()\n",
    "    json_stuff = response_json['list']\n",
    "    n += 1\n",
    "    print(f'Request #{n}: Success!')\n",
    "    print(f\"next offset: {response_json['next_offset']}\")\n",
    "    \n",
    "    # If the list is empty in the json data\n",
    "    if not json_stuff:\n",
    "        break\n",
    "    \n",
    "    for x in range(0,len(json_stuff)):\n",
    "        if json_stuff[x]['performed_by'].upper() == id_2.upper():\n",
    "            mining_list.append(json_stuff[x])\n",
    "            print(f'Processing record index #{offset + x}: {offset}, #{x}')\n",
    "\n",
    "    offset = response_json['next_offset']\n",
    "    \n",
    "    # Get out of the while loop since there is no more data to request\n",
    "    if offset == -1:\n",
    "        print(f'No more records to be processed. Total Loops: {n}')\n",
    "        break\n",
    "        \n",
    "# Did the loop finish? If not, redo this and change the `offset` above to pick up where the loop ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapped all the wanted field from the data mining + rename field\n",
    "def create_song_list(track):\n",
    "    key = track['key']\n",
    "    title = track['title']\n",
    "    artist = track['artist']\n",
    "    date = track['created_at']\n",
    "    inviter = track['performed_by']\n",
    "    recording_base_url = 'https://www.smule.com'\n",
    "    recording_url = recording_base_url + track['web_url']\n",
    "    \n",
    "    return {\n",
    "        'key': key,\n",
    "        'Title': title,\n",
    "        'Artist': artist,\n",
    "        'Date_Created': date,\n",
    "        'Invite_Spawner': inviter,\n",
    "        'URL': recording_url\n",
    "    }\n",
    "    \n",
    "# Use map to give a list iterator\n",
    "song_list_iterator = map(create_song_list, mining_list)\n",
    "# Turn iterator into a list\n",
    "join_id2_list = list(song_list_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To dataframe and transform date string\n",
    "id1_songs_df = pd.DataFrame(join_id2_list)\n",
    "id1_songs_df['Date_Created'] = id1_songs_df['Date_Created'].str.split('T').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'How many songs did {id_1} join {id_2} in total?')\n",
    "join_id1 = len(id1_songs_df)\n",
    "print(join_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save first result to csv\n",
    "id1_songs_df.to_csv('id1_songs.csv', encoding='utf_8_sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id_2 is the VIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWITCH YOUR IP ADDRESS - USE VPN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables + new empty list to restart for id_2 \n",
    "# You can use the same list but you will have to adjust everything else below\n",
    "mining_list_another = [] \n",
    "n = 0\n",
    "offset = 0\n",
    "# REMINDER: You will need to change the offset if the while loop doesn't finish in the next block. \n",
    "# Get the last next_offset from the print message before the request becomes unsuccessful.\n",
    "# Comment out the n = 0 if you want to see the total amount of request ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run another infinite loop again - if you run this again with the same IP address, you WILL get a 418 code\n",
    "# Again, USE VPN!\n",
    "\n",
    "while True:\n",
    "    response = requests.get(f'{user_2}{offset}')\n",
    "    print(f'response code: {response.status_code}')\n",
    "    \n",
    "    # Get out of the loop if request is unsuccessful\n",
    "    if response.status_code != 200:\n",
    "        print('Unsuccessful Request T^T')\n",
    "        break\n",
    "    \n",
    "    # Continue to data request\n",
    "    response_json = response.json()\n",
    "    json_stuff = response_json['list']\n",
    "    n += 1\n",
    "    print(f'Request #{n}: Success!')\n",
    "    print(f\"next offset: {response_json['next_offset']}\")\n",
    "    \n",
    "    # If the list is empty in the json data\n",
    "    if not json_stuff:\n",
    "        break\n",
    "    \n",
    "    for x in range(0,len(json_stuff)):\n",
    "        if json_stuff[x]['performed_by'].upper() == id_1.upper():\n",
    "            mining_list_another.append(json_stuff[x])\n",
    "            print(f'Processing record index #{offset + x}: {offset}, #{x}')\n",
    "\n",
    "    offset = response_json['next_offset']\n",
    "    \n",
    "    # Get out of the while loop since there is no more data to request\n",
    "    if offset == -1:\n",
    "        print(f'No more records to be processed. Total Loops: {n}')\n",
    "        break\n",
    "        \n",
    "# Did the loop finish? If not, redo this and change the `offset` above to pick up where the loop ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapped all the wanted field from the data mining + rename field\n",
    "def create_song_list(track):\n",
    "    key = track['key']\n",
    "    title = track['title']\n",
    "    artist = track['artist']\n",
    "    date = track['created_at']\n",
    "    inviter = track['performed_by']\n",
    "    recording_base_url = 'https://www.smule.com'\n",
    "    recording_url = recording_base_url + track['web_url']\n",
    "    \n",
    "    return {\n",
    "        'key': key,\n",
    "        'Title': title,\n",
    "        'Artist': artist,\n",
    "        'Date_Created': date,\n",
    "        'Invite_Spawner': inviter,\n",
    "        'URL': recording_url\n",
    "    }\n",
    "    \n",
    "# Use map to give a list iterator\n",
    "song_list_iterator = map(create_song_list, mining_list_another)\n",
    "# Turn iterator into a list\n",
    "join_id1_list = list(song_list_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To dataframe and transform date string\n",
    "id2_songs_df = pd.DataFrame(join_id1_list)\n",
    "id2_songs_df['Date_Created'] = id2_songs_df['Date_Created'].str.split('T').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'How many songs did {id_2} join {id_1} in total?')\n",
    "join_id2 = len(join_id1_list)\n",
    "print(join_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 2nd result to csv - in case there's a black out.. you know..\n",
    "id2_songs_df.to_csv('id2_songs.csv', encoding='utf_8_sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the two csv/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv of both files as df - for just-in-case usage\n",
    "# id1_songs_df = pd.read_csv('id1_songs.csv')\n",
    "# id2_songs_df = pd.read_csv('id2_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to the original dataframe\n",
    "all_songs_df = id1_songs_df.append(id2_songs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the df by date\n",
    "all_songs_df = all_songs_df.sort_values('Date_Created', ascending=False)\n",
    "\n",
    "# Reset index\n",
    "all_songs_df.reset_index(inplace=True)\n",
    "\n",
    "# Delete old index\n",
    "del all_songs_df['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Product ðŸ¤©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta-da!\n",
    "print(f'{id_1} joined {id_2} on {join_id2} songs!')\n",
    "print(f'{id_2} joined {id_1} on {join_id1} songs!')\n",
    "print(f'You guys have made {join_id2 + join_id1} recordings together as of this date.')\n",
    "\n",
    "all_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a csv with encoding that allows foreign character\n",
    "all_songs_df.to_csv('all_songs.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
